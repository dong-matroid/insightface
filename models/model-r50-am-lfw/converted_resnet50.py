import keras
from keras.models import Model
from keras import layers, initializers
import keras.backend as K
import numpy as np
import traceback

def load_weights_from_file(weight_file):
    try:
        weights_dict = np.load(weight_file).item()
    except:
        weights_dict = np.load(weight_file, encoding='bytes').item()

    return weights_dict


def set_layer_weights(model, weights_dict):
    for layer in model.layers:
        if layer.name in weights_dict:
            cur_dict = weights_dict[layer.name]
            current_layer_parameters = list()
            if layer.__class__.__name__ == "BatchNormalization":
                if 'scale' in cur_dict:
                    current_layer_parameters.append(cur_dict['scale'])
                if 'bias' in cur_dict:
                    current_layer_parameters.append(cur_dict['bias'])
                current_layer_parameters.extend([cur_dict['mean'], cur_dict['var']])
            elif layer.__class__.__name__ == "SeparableConv2D":
                current_layer_parameters = [cur_dict['depthwise_filter'], cur_dict['pointwise_filter']]
                if 'bias' in cur_dict:
                    current_layer_parameters.append(cur_dict['bias'])
            elif layer.__class__.__name__ == 'PReLU':
                current_layer_parameters = [cur_dict['gamma'].reshape(1, 1, -1)]
            else:
                # rot weights
                current_layer_parameters = [cur_dict['weights']]
                if 'bias' in cur_dict:
                    current_layer_parameters.append(cur_dict['bias'])
            try:
              model.get_layer(layer.name).set_weights(current_layer_parameters)
            except Exception as e:
              print('failed to set weight for %s' % layer.name)
              traceback.print_exc()

    return model


def KitModel(weight_file = None):
    weights_dict = load_weights_from_file(weight_file) if not weight_file == None else None

    data            = layers.Input(name = 'data', shape = (112, 112, 3,) )
    mulscalar0 =  layers.Lambda(lambda x: (x - 127.5)*0.0078125)(data)
    conv0_input     = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(mulscalar0)
    conv0           = convolution(weights_dict, name='conv0', input=conv0_input, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    bn0             = layers.BatchNormalization(momentum=0.9, name = 'bn0', axis = 3, epsilon = 2e-05, center = True, scale = True)(conv0)
    relu0 = layers.PReLU(initializers.Constant(0.25), name = 'relu0', shared_axes=[1, 2])(bn0)
    stage1_unit1_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit1_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(relu0)
    stage1_unit1_conv1sc = convolution(weights_dict, name='stage1_unit1_conv1sc', input=relu0, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(1, 1), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage1_unit1_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage1_unit1_bn1)
    stage1_unit1_conv1 = convolution(weights_dict, name='stage1_unit1_conv1', input=stage1_unit1_conv1_input, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage1_unit1_sc = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit1_sc', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage1_unit1_conv1sc)
    stage1_unit1_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit1_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage1_unit1_conv1)
    stage1_unit1_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage1_unit1_relu1', shared_axes=[1, 2])(stage1_unit1_bn2)
    stage1_unit1_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage1_unit1_relu1)
    stage1_unit1_conv2 = convolution(weights_dict, name='stage1_unit1_conv2', input=stage1_unit1_conv2_input, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage1_unit1_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit1_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage1_unit1_conv2)
    plus0           = layers.add(name = 'plus0', inputs = [stage1_unit1_bn3, stage1_unit1_sc])
    stage1_unit2_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit2_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus0)
    stage1_unit2_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage1_unit2_bn1)
    stage1_unit2_conv1 = convolution(weights_dict, name='stage1_unit2_conv1', input=stage1_unit2_conv1_input, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage1_unit2_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit2_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage1_unit2_conv1)
    stage1_unit2_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage1_unit2_relu1', shared_axes=[1, 2])(stage1_unit2_bn2)
    stage1_unit2_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage1_unit2_relu1)
    stage1_unit2_conv2 = convolution(weights_dict, name='stage1_unit2_conv2', input=stage1_unit2_conv2_input, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage1_unit2_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit2_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage1_unit2_conv2)
    plus1           = layers.add(name = 'plus1', inputs = [stage1_unit2_bn3, plus0])
    stage1_unit3_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit3_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus1)
    stage1_unit3_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage1_unit3_bn1)
    stage1_unit3_conv1 = convolution(weights_dict, name='stage1_unit3_conv1', input=stage1_unit3_conv1_input, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage1_unit3_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit3_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage1_unit3_conv1)
    stage1_unit3_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage1_unit3_relu1', shared_axes=[1, 2])(stage1_unit3_bn2)
    stage1_unit3_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage1_unit3_relu1)
    stage1_unit3_conv2 = convolution(weights_dict, name='stage1_unit3_conv2', input=stage1_unit3_conv2_input, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage1_unit3_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage1_unit3_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage1_unit3_conv2)
    plus2           = layers.add(name = 'plus2', inputs = [stage1_unit3_bn3, plus1])
    stage2_unit1_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit1_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus2)
    stage2_unit1_conv1sc = convolution(weights_dict, name='stage2_unit1_conv1sc', input=plus2, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(1, 1), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit1_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage2_unit1_bn1)
    stage2_unit1_conv1 = convolution(weights_dict, name='stage2_unit1_conv1', input=stage2_unit1_conv1_input, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit1_sc = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit1_sc', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit1_conv1sc)
    stage2_unit1_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit1_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit1_conv1)
    stage2_unit1_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage2_unit1_relu1', shared_axes=[1, 2])(stage2_unit1_bn2)
    stage2_unit1_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage2_unit1_relu1)
    stage2_unit1_conv2 = convolution(weights_dict, name='stage2_unit1_conv2', input=stage2_unit1_conv2_input, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit1_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit1_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit1_conv2)
    plus3           = layers.add(name = 'plus3', inputs = [stage2_unit1_bn3, stage2_unit1_sc])
    stage2_unit2_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit2_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus3)
    stage2_unit2_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage2_unit2_bn1)
    stage2_unit2_conv1 = convolution(weights_dict, name='stage2_unit2_conv1', input=stage2_unit2_conv1_input, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit2_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit2_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit2_conv1)
    stage2_unit2_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage2_unit2_relu1', shared_axes=[1, 2])(stage2_unit2_bn2)
    stage2_unit2_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage2_unit2_relu1)
    stage2_unit2_conv2 = convolution(weights_dict, name='stage2_unit2_conv2', input=stage2_unit2_conv2_input, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit2_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit2_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit2_conv2)
    plus4           = layers.add(name = 'plus4', inputs = [stage2_unit2_bn3, plus3])
    stage2_unit3_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit3_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus4)
    stage2_unit3_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage2_unit3_bn1)
    stage2_unit3_conv1 = convolution(weights_dict, name='stage2_unit3_conv1', input=stage2_unit3_conv1_input, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit3_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit3_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit3_conv1)
    stage2_unit3_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage2_unit3_relu1', shared_axes=[1, 2])(stage2_unit3_bn2)
    stage2_unit3_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage2_unit3_relu1)
    stage2_unit3_conv2 = convolution(weights_dict, name='stage2_unit3_conv2', input=stage2_unit3_conv2_input, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit3_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit3_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit3_conv2)
    plus5           = layers.add(name = 'plus5', inputs = [stage2_unit3_bn3, plus4])
    stage2_unit4_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit4_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus5)
    stage2_unit4_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage2_unit4_bn1)
    stage2_unit4_conv1 = convolution(weights_dict, name='stage2_unit4_conv1', input=stage2_unit4_conv1_input, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit4_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit4_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit4_conv1)
    stage2_unit4_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage2_unit4_relu1', shared_axes=[1, 2])(stage2_unit4_bn2)
    stage2_unit4_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage2_unit4_relu1)
    stage2_unit4_conv2 = convolution(weights_dict, name='stage2_unit4_conv2', input=stage2_unit4_conv2_input, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage2_unit4_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage2_unit4_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage2_unit4_conv2)
    plus6           = layers.add(name = 'plus6', inputs = [stage2_unit4_bn3, plus5])
    stage3_unit1_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit1_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus6)
    stage3_unit1_conv1sc = convolution(weights_dict, name='stage3_unit1_conv1sc', input=plus6, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit1_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit1_bn1)
    stage3_unit1_conv1 = convolution(weights_dict, name='stage3_unit1_conv1', input=stage3_unit1_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit1_sc = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit1_sc', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit1_conv1sc)
    stage3_unit1_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit1_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit1_conv1)
    stage3_unit1_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit1_relu1', shared_axes=[1, 2])(stage3_unit1_bn2)
    stage3_unit1_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit1_relu1)
    stage3_unit1_conv2 = convolution(weights_dict, name='stage3_unit1_conv2', input=stage3_unit1_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit1_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit1_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit1_conv2)
    plus7           = layers.add(name = 'plus7', inputs = [stage3_unit1_bn3, stage3_unit1_sc])
    stage3_unit2_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit2_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus7)
    stage3_unit2_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit2_bn1)
    stage3_unit2_conv1 = convolution(weights_dict, name='stage3_unit2_conv1', input=stage3_unit2_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit2_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit2_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit2_conv1)
    stage3_unit2_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit2_relu1', shared_axes=[1, 2])(stage3_unit2_bn2)
    stage3_unit2_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit2_relu1)
    stage3_unit2_conv2 = convolution(weights_dict, name='stage3_unit2_conv2', input=stage3_unit2_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit2_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit2_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit2_conv2)
    plus8           = layers.add(name = 'plus8', inputs = [stage3_unit2_bn3, plus7])
    stage3_unit3_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit3_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus8)
    stage3_unit3_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit3_bn1)
    stage3_unit3_conv1 = convolution(weights_dict, name='stage3_unit3_conv1', input=stage3_unit3_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit3_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit3_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit3_conv1)
    stage3_unit3_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit3_relu1', shared_axes=[1, 2])(stage3_unit3_bn2)
    stage3_unit3_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit3_relu1)
    stage3_unit3_conv2 = convolution(weights_dict, name='stage3_unit3_conv2', input=stage3_unit3_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit3_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit3_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit3_conv2)
    plus9           = layers.add(name = 'plus9', inputs = [stage3_unit3_bn3, plus8])
    stage3_unit4_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit4_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus9)
    stage3_unit4_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit4_bn1)
    stage3_unit4_conv1 = convolution(weights_dict, name='stage3_unit4_conv1', input=stage3_unit4_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit4_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit4_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit4_conv1)
    stage3_unit4_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit4_relu1', shared_axes=[1, 2])(stage3_unit4_bn2)
    stage3_unit4_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit4_relu1)
    stage3_unit4_conv2 = convolution(weights_dict, name='stage3_unit4_conv2', input=stage3_unit4_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit4_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit4_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit4_conv2)
    plus10          = layers.add(name = 'plus10', inputs = [stage3_unit4_bn3, plus9])
    stage3_unit5_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit5_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus10)
    stage3_unit5_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit5_bn1)
    stage3_unit5_conv1 = convolution(weights_dict, name='stage3_unit5_conv1', input=stage3_unit5_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit5_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit5_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit5_conv1)
    stage3_unit5_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit5_relu1', shared_axes=[1, 2])(stage3_unit5_bn2)
    stage3_unit5_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit5_relu1)
    stage3_unit5_conv2 = convolution(weights_dict, name='stage3_unit5_conv2', input=stage3_unit5_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit5_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit5_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit5_conv2)
    plus11          = layers.add(name = 'plus11', inputs = [stage3_unit5_bn3, plus10])
    stage3_unit6_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit6_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus11)
    stage3_unit6_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit6_bn1)
    stage3_unit6_conv1 = convolution(weights_dict, name='stage3_unit6_conv1', input=stage3_unit6_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit6_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit6_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit6_conv1)
    stage3_unit6_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit6_relu1', shared_axes=[1, 2])(stage3_unit6_bn2)
    stage3_unit6_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit6_relu1)
    stage3_unit6_conv2 = convolution(weights_dict, name='stage3_unit6_conv2', input=stage3_unit6_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit6_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit6_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit6_conv2)
    plus12          = layers.add(name = 'plus12', inputs = [stage3_unit6_bn3, plus11])
    stage3_unit7_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit7_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus12)
    stage3_unit7_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit7_bn1)
    stage3_unit7_conv1 = convolution(weights_dict, name='stage3_unit7_conv1', input=stage3_unit7_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit7_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit7_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit7_conv1)
    stage3_unit7_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit7_relu1', shared_axes=[1, 2])(stage3_unit7_bn2)
    stage3_unit7_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit7_relu1)
    stage3_unit7_conv2 = convolution(weights_dict, name='stage3_unit7_conv2', input=stage3_unit7_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit7_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit7_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit7_conv2)
    plus13          = layers.add(name = 'plus13', inputs = [stage3_unit7_bn3, plus12])
    stage3_unit8_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit8_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus13)
    stage3_unit8_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit8_bn1)
    stage3_unit8_conv1 = convolution(weights_dict, name='stage3_unit8_conv1', input=stage3_unit8_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit8_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit8_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit8_conv1)
    stage3_unit8_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit8_relu1', shared_axes=[1, 2])(stage3_unit8_bn2)
    stage3_unit8_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit8_relu1)
    stage3_unit8_conv2 = convolution(weights_dict, name='stage3_unit8_conv2', input=stage3_unit8_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit8_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit8_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit8_conv2)
    plus14          = layers.add(name = 'plus14', inputs = [stage3_unit8_bn3, plus13])
    stage3_unit9_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit9_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus14)
    stage3_unit9_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit9_bn1)
    stage3_unit9_conv1 = convolution(weights_dict, name='stage3_unit9_conv1', input=stage3_unit9_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit9_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit9_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit9_conv1)
    stage3_unit9_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit9_relu1', shared_axes=[1, 2])(stage3_unit9_bn2)
    stage3_unit9_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit9_relu1)
    stage3_unit9_conv2 = convolution(weights_dict, name='stage3_unit9_conv2', input=stage3_unit9_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit9_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit9_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit9_conv2)
    plus15          = layers.add(name = 'plus15', inputs = [stage3_unit9_bn3, plus14])
    stage3_unit10_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit10_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus15)
    stage3_unit10_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit10_bn1)
    stage3_unit10_conv1 = convolution(weights_dict, name='stage3_unit10_conv1', input=stage3_unit10_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit10_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit10_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit10_conv1)
    stage3_unit10_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit10_relu1', shared_axes=[1, 2])(stage3_unit10_bn2)
    stage3_unit10_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit10_relu1)
    stage3_unit10_conv2 = convolution(weights_dict, name='stage3_unit10_conv2', input=stage3_unit10_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit10_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit10_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit10_conv2)
    plus16          = layers.add(name = 'plus16', inputs = [stage3_unit10_bn3, plus15])
    stage3_unit11_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit11_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus16)
    stage3_unit11_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit11_bn1)
    stage3_unit11_conv1 = convolution(weights_dict, name='stage3_unit11_conv1', input=stage3_unit11_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit11_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit11_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit11_conv1)
    stage3_unit11_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit11_relu1', shared_axes=[1, 2])(stage3_unit11_bn2)
    stage3_unit11_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit11_relu1)
    stage3_unit11_conv2 = convolution(weights_dict, name='stage3_unit11_conv2', input=stage3_unit11_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit11_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit11_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit11_conv2)
    plus17          = layers.add(name = 'plus17', inputs = [stage3_unit11_bn3, plus16])
    stage3_unit12_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit12_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus17)
    stage3_unit12_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit12_bn1)
    stage3_unit12_conv1 = convolution(weights_dict, name='stage3_unit12_conv1', input=stage3_unit12_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit12_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit12_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit12_conv1)
    stage3_unit12_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit12_relu1', shared_axes=[1, 2])(stage3_unit12_bn2)
    stage3_unit12_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit12_relu1)
    stage3_unit12_conv2 = convolution(weights_dict, name='stage3_unit12_conv2', input=stage3_unit12_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit12_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit12_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit12_conv2)
    plus18          = layers.add(name = 'plus18', inputs = [stage3_unit12_bn3, plus17])
    stage3_unit13_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit13_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus18)
    stage3_unit13_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit13_bn1)
    stage3_unit13_conv1 = convolution(weights_dict, name='stage3_unit13_conv1', input=stage3_unit13_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit13_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit13_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit13_conv1)
    stage3_unit13_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit13_relu1', shared_axes=[1, 2])(stage3_unit13_bn2)
    stage3_unit13_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit13_relu1)
    stage3_unit13_conv2 = convolution(weights_dict, name='stage3_unit13_conv2', input=stage3_unit13_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit13_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit13_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit13_conv2)
    plus19          = layers.add(name = 'plus19', inputs = [stage3_unit13_bn3, plus18])
    stage3_unit14_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit14_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus19)
    stage3_unit14_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit14_bn1)
    stage3_unit14_conv1 = convolution(weights_dict, name='stage3_unit14_conv1', input=stage3_unit14_conv1_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit14_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit14_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit14_conv1)
    stage3_unit14_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage3_unit14_relu1', shared_axes=[1, 2])(stage3_unit14_bn2)
    stage3_unit14_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage3_unit14_relu1)
    stage3_unit14_conv2 = convolution(weights_dict, name='stage3_unit14_conv2', input=stage3_unit14_conv2_input, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage3_unit14_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage3_unit14_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage3_unit14_conv2)
    plus20          = layers.add(name = 'plus20', inputs = [stage3_unit14_bn3, plus19])
    stage4_unit1_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit1_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus20)
    stage4_unit1_conv1sc = convolution(weights_dict, name='stage4_unit1_conv1sc', input=plus20, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage4_unit1_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage4_unit1_bn1)
    stage4_unit1_conv1 = convolution(weights_dict, name='stage4_unit1_conv1', input=stage4_unit1_conv1_input, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage4_unit1_sc = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit1_sc', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage4_unit1_conv1sc)
    stage4_unit1_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit1_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage4_unit1_conv1)
    stage4_unit1_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage4_unit1_relu1', shared_axes=[1, 2])(stage4_unit1_bn2)
    stage4_unit1_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage4_unit1_relu1)
    stage4_unit1_conv2 = convolution(weights_dict, name='stage4_unit1_conv2', input=stage4_unit1_conv2_input, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage4_unit1_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit1_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage4_unit1_conv2)
    plus21          = layers.add(name = 'plus21', inputs = [stage4_unit1_bn3, stage4_unit1_sc])
    stage4_unit2_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit2_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus21)
    stage4_unit2_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage4_unit2_bn1)
    stage4_unit2_conv1 = convolution(weights_dict, name='stage4_unit2_conv1', input=stage4_unit2_conv1_input, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage4_unit2_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit2_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage4_unit2_conv1)
    stage4_unit2_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage4_unit2_relu1', shared_axes=[1, 2])(stage4_unit2_bn2)
    stage4_unit2_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage4_unit2_relu1)
    stage4_unit2_conv2 = convolution(weights_dict, name='stage4_unit2_conv2', input=stage4_unit2_conv2_input, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage4_unit2_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit2_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage4_unit2_conv2)
    plus22          = layers.add(name = 'plus22', inputs = [stage4_unit2_bn3, plus21])
    stage4_unit3_bn1 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit3_bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus22)
    stage4_unit3_conv1_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage4_unit3_bn1)
    stage4_unit3_conv1 = convolution(weights_dict, name='stage4_unit3_conv1', input=stage4_unit3_conv1_input, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage4_unit3_bn2 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit3_bn2', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage4_unit3_conv1)
    stage4_unit3_relu1 = layers.PReLU(initializers.Constant(0.25), name = 'stage4_unit3_relu1', shared_axes=[1, 2])(stage4_unit3_bn2)
    stage4_unit3_conv2_input = layers.ZeroPadding2D(padding = ((1, 1), (1, 1)))(stage4_unit3_relu1)
    stage4_unit3_conv2 = convolution(weights_dict, name='stage4_unit3_conv2', input=stage4_unit3_conv2_input, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='valid', use_bias=False)
    stage4_unit3_bn3 = layers.BatchNormalization(momentum=0.9, name = 'stage4_unit3_bn3', axis = 3, epsilon = 2e-05, center = True, scale = True)(stage4_unit3_conv2)
    plus23          = layers.add(name = 'plus23', inputs = [stage4_unit3_bn3, plus22])
    bn1             = layers.BatchNormalization(momentum=0.9, name = 'bn1', axis = 3, epsilon = 2e-05, center = True, scale = True)(plus23)
    dropout0        = layers.Dropout(name = 'dropout0', rate = 0.4, seed = None)(bn1)
    flatten0 = layers.Flatten(name = 'flatten0')(dropout0)
    pre_fc1         = layers.Dense(name = 'pre_fc1', units = 512, use_bias = True)(flatten0)
    fc1             = layers.BatchNormalization(momentum=0.9, name = 'fc1', axis = 1, epsilon = 2e-05, center = True, scale = False)(pre_fc1)
    model           = Model(inputs = [data], outputs = [fc1])
    model.summary()
    set_layer_weights(model, weights_dict)
    return model

def convolution(weights_dict, name, input, group, conv_type, filters=None, **kwargs):
    if not conv_type.startswith('layer'):
        layer = keras.applications.mobilenet.DepthwiseConv2D(name=name, **kwargs)(input)
        return layer

    grouped_channels = int(filters / group)
    group_list = []

    if group == 1:
        func = getattr(layers, conv_type.split('.')[-1])
        layer = func(name = name, filters = filters, **kwargs)(input)
        return layer

    weight_groups = list()
    if not weights_dict == None:
        w = np.array(weights_dict[name]['weights'])
        weight_groups = np.split(w, indices_or_sections=group, axis=-1)

    for c in range(group):
        x = layers.Lambda(lambda z: z[:, :, :, c * grouped_channels:(c + 1) * grouped_channels])(input)
        x = layers.Conv2D(name=name + "_" + str(c), filters=grouped_channels, **kwargs)(x)
        weights_dict[name + "_" + str(c)] = dict()
        weights_dict[name + "_" + str(c)]['weights'] = weight_groups[c]

        group_list.append(x)

    layer = layers.concatenate(group_list, axis = -1)

    if 'bias' in weights_dict[name]:
        b = K.variable(weights_dict[name]['bias'], name = name + "_bias")
        layer = layer + b
    return layer

if __name__ == '__main__':
  import sys

  model = KitModel(sys.argv[1])
  model.save_weights(sys.argv[1].replace('.npy', '_weights.h5'))
  model.save(sys.argv[1].replace('.npy', '.h5'))
